{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshalphonse/Bmf-Huggingface/blob/main/time_Try_HuggingFace_Overlay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpWqWB-66qcq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Joshalphonse/Bmf-Huggingface.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3KAY8NcHi2X"
      },
      "outputs": [],
      "source": [
        "!pip install BabitMF-GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq0J09rfH4lq"
      },
      "outputs": [],
      "source": [
        "!pip install requests diffusers transformers torch accelerate scipy safetensors moviepy Pillow tqdm numpy modelscope==1.4.2 open_clip_torch pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV3Q1r9oHiwZ"
      },
      "outputs": [],
      "source": [
        "!sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cq6-2SrHqhc"
      },
      "outputs": [],
      "source": [
        "!dpkg -l | grep -i ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17QW7eP3HsaZ"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ5uvumWHtFq"
      },
      "outputs": [],
      "source": [
        "!pip install wurlitzer\n",
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgC64JaR7CrV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/Bmf-Huggingface')\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRPPfgCpH8mf"
      },
      "outputs": [],
      "source": [
        "import bmf\n",
        "from bmf import bmf_sync, Packet\n",
        "from bmf import SubGraph\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of a panda eating waffles\"\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "image.save(\"panda_photo.png\")\n",
        "\n",
        "\n",
        "class video_overlay(SubGraph):\n",
        "\n",
        "\n",
        "\n",
        "    def create_graph(self, option=None):\n",
        "        # create source stream\n",
        "        self.inputs.append('source')\n",
        "        source_stream = self.graph.input_stream('source')\n",
        "        # create overlay stream\n",
        "        overlay_streams = []\n",
        "        for (i, _) in enumerate(option['overlays']):\n",
        "            self.inputs.append('overlay_' + str(i))\n",
        "            overlay_streams.append(self.graph.input_stream('overlay_' + str(i)))\n",
        "\n",
        "        # pre-processing for source layer\n",
        "        info = option['source']\n",
        "        output_stream = (\n",
        "            source_stream.scale(info['width'], info['height'])\n",
        "                .trim(start=info['start'], duration=info['duration'])\n",
        "                .setpts('PTS-STARTPTS')\n",
        "        )\n",
        "\n",
        "        # overlay processing\n",
        "        for (i, overlay_stream) in enumerate(overlay_streams):\n",
        "            overlay_info = option['overlays'][i]\n",
        "\n",
        "            # overlay layer pre-processing\n",
        "            p_overlay_stream = (\n",
        "                overlay_stream.scale(overlay_info['width'], overlay_info['height'])\n",
        "                    .loop(loop=overlay_info['loop'], size=10000)\n",
        "                    .setpts('PTS+%f/TB' % (overlay_info['start']))\n",
        "            )\n",
        "\n",
        "            # calculate overlay parameter\n",
        "            x = 'if(between(t,%f,%f),%s,NAN)' % (overlay_info['start'],\n",
        "                                                 overlay_info['start'] + overlay_info['duration'],\n",
        "                                                 str(overlay_info['pox_x']))\n",
        "            y = 'if(between(t,%f,%f),%s,NAN)' % (overlay_info['start'],\n",
        "                                                 overlay_info['start'] + overlay_info['duration'],\n",
        "                                                 str(overlay_info['pox_y']))\n",
        "            if overlay_info['loop'] == -1:\n",
        "                repeat_last = 0\n",
        "                shortest = 1\n",
        "            else:\n",
        "                repeat_last = overlay_info['repeat_last']\n",
        "                shortest = 1\n",
        "\n",
        "            # do overlay\n",
        "            output_stream = (\n",
        "                output_stream.overlay(p_overlay_stream, x=x, y=y,\n",
        "                                      repeatlast=repeat_last)\n",
        "            )\n",
        "\n",
        "        # finish creating graph\n",
        "        self.output_streams = self.finish_create_graph([output_stream])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-R4ciVfHtAl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU is available!')\n",
        "else:\n",
        "    print('GPU is not available!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjp5tiWdH2MP"
      },
      "outputs": [],
      "source": [
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECfvpRMKLGB8"
      },
      "outputs": [],
      "source": [
        "input_video_path = \"/content/Bmf-Huggingface/black_and_white.mp4\"\n",
        "logo_path = \"/content/panda_photo.png\"\n",
        "output_path = \"./complex_edit.mp4\"\n",
        "dump_graph = 0\n",
        "\n",
        "duration = 10\n",
        "\n",
        "overlay_option = {\n",
        "    \"dump_graph\": dump_graph,\n",
        "    \"source\": {\n",
        "        \"start\": 0,\n",
        "        \"duration\": duration,\n",
        "        \"width\": 1280,\n",
        "        \"height\": 720\n",
        "    },\n",
        "    \"overlays\": [\n",
        "        {\n",
        "            \"start\": 0,\n",
        "            \"duration\": duration,\n",
        "            \"width\": 300,\n",
        "            \"height\": 200,\n",
        "            \"pox_x\": 0,\n",
        "            \"pox_y\": 0,\n",
        "            \"loop\": 0,\n",
        "            \"repeat_last\": 1\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "my_graph = bmf.graph({\n",
        "    \"dump_graph\": dump_graph\n",
        "})\n",
        "\n",
        "logo_1 = my_graph.decode({'input_path': logo_path})['video']\n",
        "\n",
        "video1 = my_graph.decode({'input_path': input_video_path})\n",
        "\n",
        "overlay_streams = list()\n",
        "overlay_streams.append(bmf.module([video1['video'], logo_1], 'video_overlay', overlay_option, entry='__main__.video_overlay')[0])\n",
        "\n",
        "bmf.encode(\n",
        "    overlay_streams[0],\n",
        "    video1['audio'],\n",
        "    {\"output_path\": output_path}\n",
        "    ).run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xIefZq8U4qR"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, video_width = 800):\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return f\"\"\"\n",
        "  <video width={video_width} controls>\n",
        "    <source src=\"{video_url}\">\n",
        "  </video>\n",
        "  \"\"\"\n",
        "\n",
        "video_url1 = show_video('/content/Bmf-Huggingface/black_and_white.mp4')\n",
        "video_url2 = show_video('complex_edit.mp4')\n",
        "\n",
        "html = video_url1 + video_url2\n",
        "HTML(html)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}